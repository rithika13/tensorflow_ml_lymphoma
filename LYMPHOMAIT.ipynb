{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1bG4wZtFIFI"
      },
      "source": [
        "LYMPHOMA CLASSIFICATION PROJECT\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7p75dB_wFc5a"
      },
      "source": [
        "Importing Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AnfLr4biE8lT"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers import Input, Lambda, Dense, Flatten\n",
        "from keras.models import Model\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from glob import glob\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.applications import imagenet_utils\n",
        "from sklearn.metrics import confusion_matrix\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Functions for automating the pre-processing tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKtlbaAjFhX2"
      },
      "outputs": [],
      "source": [
        "def initiateGenerator(path):\n",
        "    base_path = path\n",
        "    print(\"\\nTotal : \", end=\" \")\n",
        "    train_dataset = tf.keras.preprocessing.image_dataset_from_directory(batch_size=32, directory=base_path+\"/\"+\"train\")\n",
        "\n",
        "    train_datagen = ImageDataGenerator()\n",
        "\n",
        "    print(\"\\nFor Training : \", end=\" \")\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        base_path+\"/\"+\"train\",\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical', subset='training')\n",
        "\n",
        "    print(\"\\nFor Val : \", end=\" \")\n",
        "    valid_datagen = ImageDataGenerator()\n",
        "    validation_generator = valid_datagen.flow_from_directory(\n",
        "        base_path+\"/\"+\"val\",\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical',shuffle=False)\n",
        "    test_datagen = ImageDataGenerator()\n",
        "    test_generator = test_datagen.flow_from_directory(\n",
        "        base_path+\"/\"+\"test\",\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical', shuffle=False)\n",
        "    class_names = train_dataset.class_names\n",
        "    noOfClasses = len(class_names)\n",
        "    print(\"\\nNo of Classes : \", noOfClasses)\n",
        "    print(\"Classes : \", class_names)\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    for images, labels in train_dataset.take(1):\n",
        "        for i in range(noOfClasses):\n",
        "            ax = plt.subplot(4, 4, i + 1)\n",
        "            plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "            plt.title(class_names[labels[i]])\n",
        "            plt.axis(\"off\")\n",
        "\n",
        "    for image_batch, labels_batch in train_dataset:\n",
        "        print(\"Image Shape : \",image_batch.shape)\n",
        "        break\n",
        "\n",
        "    return noOfClasses,class_names, train_generator, validation_generator,test_generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ReI8m7_vGDJU"
      },
      "outputs": [],
      "source": [
        "def initiateNormalize():\n",
        "    AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "    train_ds = train_generator.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "    val_ds = val_generator.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "    normalization_layer = layers.Rescaling(1./255)\n",
        "\n",
        "    normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "    image_batch, labels_batch = next(iter(normalized_ds))\n",
        "    first_image = image_batch[0]\n",
        "    print(np.min(first_image), np.max(first_image))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "VGG-19 Model Creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6xwpUO7GGcG"
      },
      "outputs": [],
      "source": [
        "def initiateVGG19(noOfClasses):\n",
        "    modelInput = tf.keras.applications.VGG19(\n",
        "        input_shape=IMAGE_SIZE + [3],\n",
        "        include_top=False,\n",
        "        weights=\"imagenet\"\n",
        "    )\n",
        "\n",
        "    for layer in modelInput.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    x = Flatten()(modelInput.output)\n",
        "    prediction = Dense(noOfClasses, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=modelInput.input, outputs=prediction)\n",
        "    return model\n",
        "\n",
        "def modelSummary(model):\n",
        "    model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "DenseNet201 Model Creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTac3MS4GN0y"
      },
      "outputs": [],
      "source": [
        "def initiateDenseNet201(noOfClasses):\n",
        "    modelInput = tf.keras.applications.DenseNet201(\n",
        "        input_shape=IMAGE_SIZE + [3],\n",
        "        include_top=False,\n",
        "        weights=\"imagenet\"\n",
        "    )\n",
        "\n",
        "    for layer in modelInput.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    x = Flatten()(modelInput.output)\n",
        "    prediction = Dense(noOfClasses, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=modelInput.input, outputs=prediction)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "MobileNet Model Creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyeKSvLwGQlT"
      },
      "outputs": [],
      "source": [
        "def initiateMobileNetV3(noOfClasses):\n",
        "    modelInput = tf.keras.applications.MobileNetV3Small(\n",
        "        input_shape=IMAGE_SIZE + [3],\n",
        "        include_top=False,\n",
        "        weights=\"imagenet\"\n",
        "    )\n",
        "\n",
        "    for layer in modelInput.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    x = Flatten()(modelInput.output)\n",
        "    prediction = Dense(noOfClasses, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=modelInput.input, outputs=prediction)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QqB3znPGTpv"
      },
      "outputs": [],
      "source": [
        "def initiateParams(className, model, lr,model_name):\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "\n",
        "    model.compile(optimizer=opt,\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    annealer = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=5, verbose=1, min_lr=1e-3)\n",
        "    checkpoint = ModelCheckpoint(className + model_name+'.h5', verbose=1, save_best_only=True)\n",
        "\n",
        "    return model, annealer, checkpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Function for fitting the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwU_q_jZGWfu"
      },
      "outputs": [],
      "source": [
        "def modelFit(model, annealer, checkpoint, epochs=20, batchSize = 256):\n",
        "\n",
        "    history = model.fit(\n",
        "      train_generator,\n",
        "      validation_data=validation_generator,\n",
        "      epochs=epochs,\n",
        "      batch_size=batchSize,\n",
        "      callbacks=[annealer, checkpoint],\n",
        "      steps_per_epoch=len(train_generator),\n",
        "      validation_steps=len(validation_generator)\n",
        "    )\n",
        "\n",
        "    return history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Function for plotting the evaluation metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jzOAbvpqGZRB"
      },
      "outputs": [],
      "source": [
        "def plotOutput(history, className, epochs):\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    epochs_range = range(epochs)\n",
        "\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    plt.subplot(3, 2, 1)\n",
        "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "\n",
        "    plt.subplot(3, 2, 2)\n",
        "    plt.plot(epochs_range, loss, label='Training Loss')\n",
        "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.show()\n",
        "    plt.savefig(className + '_graph.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Function for evaluating and saving the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCzeY3F3GerK"
      },
      "outputs": [],
      "source": [
        "def evalModel(model):\n",
        "    evl = model.evaluate(test_generator)\n",
        "    acc = evl[1]*100\n",
        "    msg=f'Accuracy on the Test Set = {acc:5.2f} %'\n",
        "    print(msg)\n",
        "    return acc\n",
        "\n",
        "def saveModel(model, className,model_name):\n",
        "    model.save(className + \" - \"+model_name+\"Final.h5\")\n",
        "    print(\"Model Saved!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Function for plotting the confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REYzMO9DGlKl"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(cm,\n",
        "                          target_names,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=None,\n",
        "                          normalize=True):\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "    import itertools\n",
        "\n",
        "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
        "    misclass = 1 - accuracy\n",
        "\n",
        "    if cmap is None:\n",
        "        cmap = plt.get_cmap('Blues')\n",
        "\n",
        "    plt.figure(figsize=(15, 15))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    if target_names is not None:\n",
        "        tick_marks = np.arange(len(target_names))\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "\n",
        "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if normalize:\n",
        "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        else:\n",
        "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
        "    plt.show()\n",
        "    plt.savefig(title + '.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMIEblj3Go-s"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import recall_score,precision_score,f1_score\n",
        "def callPlot(model, className, classes):\n",
        "    y_true = test_generator.classes\n",
        "    print(\"True : \", (y_true))\n",
        "\n",
        "    y_pred = model.predict(test_generator)\n",
        "    y_pred = np.argmax(y_pred, axis=1)\n",
        "    print(\"Predicted : \", (y_pred))\n",
        "\n",
        "    conf_mat = confusion_matrix(y_true, y_pred)\n",
        "    acc=np.trace(conf_mat) / float(np.sum(conf_mat))\n",
        "    print(f\"ACCURACY={acc}\")\n",
        "    recall=recall_score(y_true,y_pred,average='weighted')\n",
        "    p=precision_score(y_true, y_pred,average='weighted')\n",
        "    f1=f1_score(y_true, y_pred,average='weighted')\n",
        "\n",
        "    print(f\"RECALL={recall}\")\n",
        "    print(f\"precision={p}\")\n",
        "    print(f\"F1 Score{f1}\")\n",
        "    plot_confusion_matrix(cm           = conf_mat,\n",
        "                          normalize    = False,\n",
        "                          target_names = classes,\n",
        "                          title        = className + \"Confusion Matrix\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhFupf8KGwok"
      },
      "outputs": [],
      "source": [
        "#Open and read the JSON file\n",
        "with open('kaggle (1).json', 'r') as json_file:\n",
        "    data = json.load(json_file)\n",
        "\n",
        "#Access specific values from the loaded JSON data\n",
        "username = data['username']\n",
        "key= data['key']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61Z1OIDjHXZu"
      },
      "outputs": [],
      "source": [
        "os.environ['KAGGLE_USERNAME'] =username\n",
        "os.environ['KAGGLE_KEY'] =key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyREmjlPHkOK",
        "outputId": "3eff460c-2291-4ddb-a692-13c19b8019d9"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d mdrabbaniuvce/multi-cancer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJPhAw-BIFAS",
        "outputId": "2561ee83-f174-4b74-f638-82a953a1635d"
      },
      "outputs": [],
      "source": [
        "!unzip multi-cancer.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UH4CVnO9Go2e"
      },
      "outputs": [],
      "source": [
        "mpath = r'Dataset'\n",
        "classPaths = os.listdir(mpath)\n",
        "\n",
        "IMAGE_SIZE = [224, 224]\n",
        "img_height = 224\n",
        "img_width = 224\n",
        "noOfClasses = 0\n",
        "gEpochs = 10\n",
        "lr = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nq6fo0PYI1-o"
      },
      "outputs": [],
      "source": [
        "import pprint\n",
        "part={}\n",
        "for c in classPaths:\n",
        "#     part[c]={'models':{\"EfficientNetB7\":{\"model\":None,\"accurary\":0},\n",
        "#                     \"Densenet201\":{\"model\":None,\"accurary\":0},\n",
        "#                     \"VGG19\":{\"model\":None,\"accurary\":0},\n",
        "#                     \"ResnetV2\":{\"model\":None,\"accurary\":0},\n",
        "#                     \"mobilenetV3\":{\"model\":None,\"accurary\":0}\n",
        "#                    },'no_of_classes':0,\"ClassNames\":None}\n",
        "    part[c]={'models':{},'no_of_classes':0,\"ClassNames\":None}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2n0mq47I3hc",
        "outputId": "ced092fe-94b4-4637-eb6b-dd923056976d"
      },
      "outputs": [],
      "source": [
        "pprint.pprint(part)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Function for ensembling the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHMw-tBUI_ri"
      },
      "outputs": [],
      "source": [
        "def Ensemble(c):\n",
        "    y_true = test_generator.classes\n",
        "    print(\"True : \", (y_true))\n",
        "    pred=[]\n",
        "    for model,obj in part[c]['models'].items():\n",
        "        pred.append(obj['model'].predict(test_generator)*obj['Accurary'])\n",
        "    y_pred=pred[0]\n",
        "    for i in range(1,len(pred)):\n",
        "        y_pred=y_pred+pred[i]\n",
        "\n",
        "    y_pred = np.argmax(y_pred, axis=1)\n",
        "    print(\"Predicted : \", (y_pred))\n",
        "\n",
        "    conf_mat = confusion_matrix(y_true, y_pred)\n",
        "    acc=np.trace(conf_mat) / float(np.sum(conf_mat))\n",
        "    print(f\"ACCURACY={acc}\")\n",
        "    recall=recall_score(y_true,y_pred,average='weighted')\n",
        "    p=precision_score(y_true, y_pred,average='weighted')\n",
        "    f1=f1_score(y_true, y_pred,average='weighted')\n",
        "    print(f\"RECALL={recall}\")\n",
        "    print(f\"precision={p}\")\n",
        "    print(f\"F1 Score{f1}\")\n",
        "\n",
        "    plot_confusion_matrix(cm           = conf_mat,\n",
        "                          normalize    = False,\n",
        "                          target_names = part[c]['ClassNames'],\n",
        "                          title        = c + \"Confusion Matrix\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxkRTUD4JBBn"
      },
      "outputs": [],
      "source": [
        "def initiateResNet50V2(noOfClasses):\n",
        "    modelInput = tf.keras.applications.ResNet50V2(\n",
        "        input_shape=IMAGE_SIZE + [3],\n",
        "        include_top=False,\n",
        "        weights=\"imagenet\"\n",
        "    )\n",
        "\n",
        "    for layer in modelInput.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    x = Flatten()(modelInput.output)\n",
        "    prediction = Dense(noOfClasses, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=modelInput.input, outputs=prediction)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5anu69GfJN3P",
        "outputId": "64401853-b42d-4c4e-8fcd-dfff79af5f95"
      },
      "outputs": [],
      "source": [
        "for c in classPaths[1:2]:\n",
        "    className = c\n",
        "#     model_name=\"VGG-19\"\n",
        "    cpath = os.path.join(mpath, c)\n",
        "    noOfClasses, class_names, train_generator, validation_generator,test_generator = initiateGenerator(cpath)\n",
        "    part[c]['ClassNames']=class_names\n",
        "\n",
        "\n",
        "\n",
        "    model_name=\"VGG-19\"\n",
        "    print(\"######################################################\")\n",
        "    print(f\"RESULTS FOR{model_name}\")\n",
        "    curVGG19 = initiateVGG19(noOfClasses)\n",
        "    #modelSummary(curVGG19)\n",
        "    curVGG19, annealer, checkpoint = initiateParams(className, curVGG19, lr,model_name)\n",
        "    curHistory = modelFit(curVGG19, annealer, checkpoint, epochs=gEpochs, batchSize=256)\n",
        "    plotOutput(curHistory, className, gEpochs)\n",
        "    acc=evalModel(curVGG19)\n",
        "\n",
        "    saveModel(curVGG19, className,model_name)\n",
        "    part[c]['models']['VGG19']={\"model\":curVGG19,'Accurary':acc}\n",
        "    callPlot(curVGG19, className, class_names)\n",
        "\n",
        "    model_name=\"DenseNet201\"\n",
        "    print(\"######################################################\")\n",
        "    print(f\"RESULTS FOR{model_name}\")\n",
        "    curDenseNet201= initiateDenseNet201(noOfClasses)\n",
        "    #modelSummary(curDenseNet201)\n",
        "    curDenseNet201, annealer, checkpoint = initiateParams(className, curDenseNet201, lr,model_name)\n",
        "    curHistory = modelFit(curDenseNet201, annealer, checkpoint, epochs=gEpochs, batchSize=256)\n",
        "    plotOutput(curHistory, className, gEpochs)\n",
        "    acc=evalModel(curDenseNet201)\n",
        "    saveModel(curDenseNet201, className,model_name)\n",
        "    part[c]['models']['DenseNet201']={\"model\":curDenseNet201,'Accurary':acc}\n",
        "    callPlot(curDenseNet201, className, class_names)\n",
        "\n",
        "\n",
        "\n",
        "    model_name=\"MobileNetV3\"\n",
        "    print(\"######################################################\")\n",
        "    print(f\"RESULTS FOR{model_name}\")\n",
        "    curMobileNetV3 = initiateMobileNetV3(noOfClasses)\n",
        "    #modelSummary(curMobileNetV3)\n",
        "    curMobileNetV3, annealer, checkpoint = initiateParams(className, curMobileNetV3, lr,model_name)\n",
        "    curHistory = modelFit(curMobileNetV3, annealer, checkpoint, epochs=gEpochs, batchSize=256)\n",
        "    plotOutput(curHistory, className, gEpochs)\n",
        "    acc=evalModel(curMobileNetV3)\n",
        "    saveModel(curMobileNetV3, className,model_name)\n",
        "    part[c]['models']['MobileNetV3']={\"model\":curMobileNetV3,'Accurary':acc}\n",
        "    callPlot(curMobileNetV3, className, class_names)\n",
        "\n",
        "    model_name=\"ResNet50V2\"\n",
        "    print(\"######################################################\")\n",
        "    print(f\"RESULTS FOR{model_name}\")\n",
        "    curResNet50V2 = initiateResNet50V2(noOfClasses)\n",
        "    #modelSummary(curResNet50V2)\n",
        "    curResNet50V2, annealer, checkpoint = initiateParams(className, curResNet50V2, lr,model_name)\n",
        "    curHistory = modelFit(curResNet50V2, annealer, checkpoint, epochs=gEpochs, batchSize=256)\n",
        "    plotOutput(curHistory, className, gEpochs)\n",
        "    acc=evalModel(curResNet50V2)\n",
        "    saveModel(curResNet50V2, className,model_name)\n",
        "    part[c]['models']['ResNet50V2']={\"model\":curResNet50V2,'Accurary':acc}\n",
        "    callPlot(curResNet50V2, className, class_names)\n",
        "    print(\"######################################################\")\n",
        "    print(f\"RESULTS FOR ENSEMBLE\")\n",
        "    Ensemble(c)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
